---
Title: ' 2. LDAによるトピック解析'
Category:
- データ解析
- 自然言語処理
- 興味分析
- トピックモデル
Date: 2014-12-23T01:05:00+09:00
URL: http://ni66ling.hatenadiary.jp/entry/20141223/1419350700
EditURL: https://blog.hatena.ne.jp/ni66ling/ni66ling.hatenadiary.jp/atom/entry/8454420450083715842
---

** はじめに
連載記事 [http://d.hatena.ne.jp/ni66ling/20141223/1419323806:title=はてブ記事を用いた興味分析] の2つ目の記事です．
ここでは，はてブに登録したWebページ全てに対して，LDA((Latent Dirichlet Allocation))によるトピック解析を行い，
はてブに登録している内容のトピック（話題，興味の対象）を分析します．
実装の前提として，[http://d.hatena.ne.jp/ni66ling/20141223/1419323344:title=データの準備（はてブからブログ記事取得・形態素解析）]が完了していることを想定しています．

** トピック解析とは？
トピック解析とは，入力データのトピック（話題，分野など，大ざっぱな「意味」）を推定することです．データの抽象化とも言えると思います．クラスタリング((k-meansクラスタリングや混合ガウス分布による確率的クラスタリングなど))におけるクラスの推定，次元圧縮((主成分分析や独立成分分析，スパースコーディングなど))における基底の推定などと非常に似ています．
本記事におけるトピック解析とは，入力のはてブ記事群におけるジャンル推定を意味します．

トピック解析の詳細は，次のページ（PDF）が分かりやすく，オススメです．
- [http://www.ism.ac.jp/~daichi/lectures/ISM-2012-TopicModels-daichi.pdf:title=確率的トピックモデル]((トピックモデルの日本語の文献では，持橋大地さんの資料が非常に分かりやすいです．))
- [http://www.cs.princeton.edu/~blei/blei-mlss-2012.pdf:title=Probabilistic Topic Modeling]((トピックモデルの提唱者B.M.Bleiさんの資料です．))

** LDAとは？
LDAとは，トピック解析手法の一つで，最も有名な手法です．
潜在意味インデキシング（LSI）((異なる表現だと，潜在意味解析（LSA），主成分分析（PCA），特異値分解（SVD），KL展開など．それぞれ詳細には異なりますが，結果的にやることは同じです．))を確率化したpLSIを完全にベイズ化した手法です．
1つの文書が複数のトピックから確率的に構成されることを仮定した言語モデルの一手法です．

グラフィカルモデルでは，下図のとおりです．
各種変数/定数に意味を赤字にて補足しました．
[f:id:ni66ling:20141223214654p:image]
計算で求めたい文字は，上図のハイパーパラメータα（トピックの分布）((トピック数Kだけのベクトル))とβ（トピックごとの単語の分布）((トピックごとに単語数Nだけのベクトル))であり，
他の文字は観測定数もしくは計算過程で用いるだけの変数です．
文字が多く，何が既知で，何が未知なのか混乱しがちですので，注意が必要です．

LDAの詳細は，次のページ/文献がわかりやすく，オススメです．
- [http://d.hatena.ne.jp/a_bicky/20130312/1363097267:title=Latent Dirichlet Allocationゆるふわ入門]
- [http://developer.smartnews.com/blog/2013/08/19/lda-based-channel-categorization-in-smartnews/:title=Latent Dirichlet Allocation(LDA)を用いたニュース記事の分類]
- [http://www.amazon.co.jp/%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%98%E3%81%A8%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92-%E4%B8%8B-%E3%83%99%E3%82%A4%E3%82%BA%E7%90%86%E8%AB%96%E3%81%AB%E3%82%88%E3%82%8B%E7%B5%B1%E8%A8%88%E7%9A%84%E4%BA%88%E6%B8%AC-C-M-%E3%83%93%E3%82%B7%E3%83%A7%E3%83%83%E3%83%97/dp/4621061240/ref=pd_sim_b_1?ie=UTF8&refRID=0N2YYSC23MK66MYBN2QQ:title=パターン認識と機械学習 下 -ベイズ理論による統計的予測]の10章((ただし，ここではLDAの説明はないです．混合ガウス分布（GMM）のベイズ化について詳細な説明があり，これのアナロジーとしてLDAを捉えると理解しやすいです．))

私も以下記事にまとめてみました．
[http://ni66ling.hatenadiary.jp/entry/2015/05/04/163958:embed:cite]


** LDAによるトピック解析とその結果
ここでは，持橋さんの[http://chasen.org/~daiti-m/dist/lda/:title=lda, a Latent Dirichlet Allocation package.]((変分ベイズによる実装です．))を用いてはてブ記事群をLDAにかけます．((ただし，はてブ記事数は2008年〜2014年までで4600程度です．))
実装の詳細は[https://github.com/KenshoFujisaki/AnalyseHatenaBookmarkLDA:title=GitHub]を参照ください．
結果，下図のようなワードクラウドを出力します．
[f:id:ni66ling:20141223233507p:image]

このワードクラウドの見方は次のとおりです．
[f:id:ni66ling:20141223233511p:image]

自分自身，何に興味があるのか，一目瞭然になりますね．面白い．．．
次回はHDP-LDA((Hierarchical Dirichlet Process-Latent Dirichlet Allocation:階層ディリクレ過程 潜在ディリクレ配分法))によるトピック数自動決定可能なトピック解析について書きます．
